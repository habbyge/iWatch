

////////////////////////////////////////////////////////////////////////////////////
// 构建自己的技术壁垒：
// 基础：终端性能、跨平台、插件化、热补丁
// 平台化：数据采集、分析平台，包括业务数据；技术参数数据等；
-> 这就是我的技术壁垒，hellhound负责采集基础数据，在其上建立具体数据系统，并利用终端的边缘计算能力，来
减轻服务端算力的压力
// 5G的普及，终端性能的提升都ok
/////////////////////////////////////////////////////////////////////////////////////

// 2月11
1.1、圈外session page 少了10%的量:   --> 已经合入了
(1) 圈外session page bug fix，已提交merge，跟随finder版本发布，
(2) 主要有两个问题：session配置有问题、主进程重启后会清理掉cache、上报效率有问题

// 2月12
2.1、手机昨天到了，debug，配置 “聊天会话中的多话题卡片” 新单 ---> ok
多话题卡片：跟业务开发沟通了需求：朋友圈、会发开放、收藏等关闭；配单已完成，并debug通过，待发布！！
待鸿业确认细节，再转发布

下个版本需求：
2.2、feed分时支持非法feed统计，也统计上报：熟悉需求、revierw代码，实现一部分 30%吧

// 2月13
feed分时支持非法feed统计，也统计上报：熟悉需求、review代码，完成并debug
重阳：hellhound框架1	.1.20新版本灰度支持，matrix线程池统计数据

// 2月14
完成：Profile timeline 分时监控；


// Android缺少的能力：2.5期能力（模糊匹配支持不限制sid、支持采集若干前置页、支持获取任意页面的业务参数、
支持数据加密）

// 2月15
周五：1、非法feed debug完成；2、timeline分时监控：Profile入口、会话入口、都已经自测并提测了；
周五：1、支持小游戏session；
都合入红版了
// 2月17(周一)
Session Page 支持采集多前置页，还没搞完；

// 2月18(周二)
昨天：Session Page 支持采集多前置页，还没搞完；-> 今天继续
今天：新增timeline分时入口页面，搞定

// 2月19(周三)
昨天：
1、Session Page 支持采集多前置页开发完成；
2、嘉敏那边的sessionPageId查问题：api调用时机bug；账号切换后下发bug；游戏session132页面乱了
3、圈外其他场景分时，跟下个版本；
今天：
1、Session Page 支持采集多前置页 debug + 再review看看还有啥遗漏没(查漏补缺)；
2、查看u0，撸准确率提升；


// 2月20(周四)
昨天：
1、Session Page 支持采集多前置页 debug + 再review看看还有啥遗漏没(查漏补缺)； ---- done
今天：
1、查看u0，撸准确率提升；
2、我reivew下之前的viewid, 可以找时间讨论viewId

// 2月20(周四)
昨天：
1、Session Page 支持采集多前置页 debug + 再review看看还有啥遗漏没(查漏补缺)； ---- 提测，
  今天封板，合入2月主干
2、查看u0，撸准确率提升；--昨天被阻塞，没搞，今天继续
3、我reivew下之前的viewid, 可以找时间讨论viewId
4、嘉敏SessionPageId为null的bug
5、视频号session进入时，误触的问题

今天：
1、查看u0，撸准确率提升；--昨天被阻塞，没搞，今天继续
2、视频号session进入时，误触的问题

/////////// 问题
1、提供更内存缓存方案，作为辅助，解决开始时拿不到sessionId的bug --> fix，合入灰度2和2月发布分支
2、143-Session(视频号)中的误触异常监控单已经配置了
3、分析聊天页面中，点击feed分享页为啥为null？ok了，有的是扫一扫入口进去的
4、review u0无效session有些多，补齐遗漏(与iOS不同的) -> 新增了两个 done
5、2月发布分支编译不过的bug：Progaurd与kotlin中的某些指令(invokestatic)排序不兼容，已经转交给
  tomytang在处理了，支持kotlin的beta版

// 2月24(周一)
1、review u0，提升准确率，异步框架中的时长同步化，还需要继续自测，今天继续debug
   review U0：LauncherUI、PermissionActivity这个页面在u0中展示不对，需要拉一些日志分析下。
   reView U0：权限弹框会导致前后台次数增加：原因已经找到，解决方案已经确定，今天完成。

2、ViewId新方案研究 可能拿不到，则用名称来代替、设置操作事件的行号范围
四种情况：关键点是是否能够拿到布局文件名、控件资源名
情况1：能拿到LayoutId和ViewId的：页面名|布局文件名|View资源名|操作事件ID
情况2：能拿到LayoutId，但拿不到ViewId的：页面名|布局文件名|View设置该操作事件的行号|操作事件ID
情况3：不能拿到LayoutId，但能拿到ViewId的：页面名|null|View资源名|操作事件ID
情况4：不能拿到LayoutId，也拿不到ViewId的：页面名|null|View设置该操作事件的行号|操作事件ID


// 2月25(周二)
1、ViewId方案研究，需要再讨论下：
1.1、行号
优点：
（1）编译期直接拿到行号，在Build包时，自动生成行号对应关系(控件ID)；
（2）无需在点击时，向上一层层回缩整个path，拿到view Path；直接读我从字节码返回的监控参数接口，不至于因
    为path太长导致的可能的性能问题
（3）无需在点击时，
缺点：每个版本发布，更容易被改变，(但是无论怎样，你都逃不过，在每个版本发布后，再重新review一遍，无论是人
工还是工具)
1.2、view Path：
缺点：
（1）动态add/或调整view层次的控件(只是代表某一个场景的ID，会导致你配置的路径跟用户点击的采集的路径不一致，
    多对一的关系)，而行号方案，无论你是啥view路径，点击的都是同一行，都能匹配上。
（2）view树的话，保证唯一性比较难，举例：你点击的两个不同的控件，属于同一个树，且控件名都相同，层级也相同。
    用序号，如果动态交换位置，如何？？
    你会在每一层中，从左到右来遍历，增加序号。。。。又增加不确定性：使用过程中，会随时gone掉任意一个控件，
    序号就被打乱了

（3）ViewPath向上回溯层级到 DocorView，会消耗点击事件耗时；


1.3、增加：除了在sessioinPage中加入的话，还需要加入uba；


// 2月26(周三)
昨天：
1、ViewId版本兼容问题，不行，控件资源ID也混淆了，这个最靠谱的ID
2、u0 review 继续发现问题：时长排序不对，从u0上展示来看，跟uba展示出来的数据不同，看了一些，uba数据正常
3、权限系统弹框(Activity)导致的前后台问题已经ok了
4、话题配置已经发了
5、灰度版本的checklist过了

今天：
1、前后台异步时长问题，完成了。
2、画个Android控件方面的，还在写，上午能完成发出来。

// (2月27)周四：
昨天：
1、前后台异步时长问题，完成了
2、画个Android控件方面的，还在写，上午能完成发出来
3、混淆问题，有些混淆问题没有被keep住，已经解决了
今天：
1、Android新版本发布，review U0上的session配单，新版本混淆看正确否
2、画个Android控件方面的，还在写，上午能完成发出来
3、继续review分析 u0上的异常情况


// (2月28)周五：
昨天：
1、前后台异步时长问题，缺个测试工具，让测试容易测试
2、讨论了Android控件方面的：接下来任务是：写个测试工具来验证；同时在研究新的直接设置id的方案；
今天：
1、控件交互；
2、控件方案研究：测试工具
3、继续review分析 u0上的异常情况

关于ViewID的思路：
1、接受到
2、


// 3月3(周二)
昨天：
（1）u0异常数据查看，学习数据平台提数，找一些uin看看为啥是异常的：页面异常、前后台次数异常
（2）FEB版本的rc1，有个并发访问的crash，修复了；今天下午会发RC-2
今天：继续
1、u0异常数据查看，学习数据平台提数，找一些uin看看为啥是异常的：页面异常
2、视频号数据异常：cell与视频号session对不上

// 3月4(周三)

昨天：视频号数据异常：cell与视频号session对不上
今天：继续多分析日志，修复bug
19份：
3份：有上报
9份：hellhound开关关闭
1个：底层获取fragment正确，但是callback回重新拿出错
1个：PermissionActivity导致上一个session没有被关闭
1个：112session没有被释放
1个：mmkv存储丢失



先同步下现在查到的问题(分析了20多份日志)，
1、先同步结论：

差的：
（1）大部分是：监控开关是关闭的或半开半闭，导致数据没有上报；
（2）小部分是：用户使用过程中，异常情况导致：进程重启、丢失某些页面事件(非只是我的监控丢失，是业务中也丢
    失该事件，导致session退出识别失败、存储失败、退出登录、异步队列接受消息发生异常，退出事件消费导致
    监控失败等)
（3）有几例是有上报的，可能是服务端丢失日志导致统计没有了；

好的：
（1）session Page逻辑未见异常（即：未见有错删、漏报等场景），说明年前的修复是有用处的；
（2）底层监控未见异常(即：用户操作和业务该有的页面事件、点击行为，hellhound都能监控准确)

2、改进
（1）对于异常的识别，采取兜底策略，例如：sessionPage识别完成，但未闭环，退出session时，依旧上报；
（2）监控开关默认打开
3、cash哥再帮忙看看finder版本还有没有补丁可发，如果没有，在feb版本跟随补丁上去：默认打开开关。


// 3月5号：周四
视频号异常，分析日志，得出，大头还是开关；少部分：用户使用过程中，异常情况导致：丢失某些页面事件导致、进程
重启、异步队列接受消息发生异常等；
解决办法：
（1）监控开关默认打开；
（2）通过框架，监控视频号每一步：点击cell、启动视频号首页、退出视频号首页、进入视频号session、退出视频号
    session为了查看哪一步丢失的多，算出一个比例，找出问题所在；
（3）识别异常，采取兜底策略，防止漏报；


// 兜底方案：
1、解决session没有close场景：
（1）解决session异常（未结束、未开始）: 4个tab reusme/pause时，判断当前是否是处于session中，如果是，
    则认为已经结束/开始；
（2）跟踪页面流每一个节点，通过历史判断获取当前期望的页面行为，来寻找

// 3月6号：周五
1、视频号灰度；开关默认打开；视频号节点上报；消息队列crash也解决了，b82还没出数据
2、feb灰度已经准备好：session未正常结束bug：有个api未使用底层上传的字段，而是从新获取一次fragment
   导致出错；
3、又看了一下日志：未打开开关12个；session未正常结束；消息队列crash；

// 兜底方案：
1、session异常兜底方案: session到4个tab保证结束；session close时保证session page进入上报队列
2、session Page 未正常finish兜底：session结束时，上报已经匹配完的页面流(未闭环)

// 3月9号 周一
兜底方案：
灰度观察：从点击到页面这里流失大

// 3月10号，周二
1、从点击cell到页面启动，原因：我的上一个session异常未结束；---在feb这次灰度中已经修复了；继续观察
   feb灰度数据点击cell到startActivity阶段的丢失：上一个session异常导致，143session不能开始
   ------ 已经修复，观察Feb数据
finish事件丢失：查找

2、控件、业务参数配置、下发流程图、交互图

// 3月11号、12号，周三、周四
1、视频号bug
继续review了一下日志，确认了问题，今天灰度。灰度1数据比之前提升了几个点
session异常未开始，未把问题解决完：业务api粗坑，导致首页4个tab，按照index获取对应不上；fix，今天灰度2
重复点击依然存在，朋友圈-视频号，看一看-视频号
getUin() api偶发性失败
-------------------------------------  等待灰度看数据，今天灰度
2、Android配置、跨版本交互图 -----未完成，今天继续
	控件、业务参数配置、流程图、交互图
3、昨天过的代码、视频号新需求：
（1）空日志过滤，还在review调试中；明显的：uba、session page、session经过debug无明显问题（时长、
    事件都无问题）
（2）session page切后台直接上报 ---完成
（3）session/uba，增加大小限制(>=20K则认为需要立马上报)；-----完成
4、控件无效id，红版比例，次数：10%左右 --------- 取出重复，控件的比例大概在2%左右

5、昨天(重阳matrix那边)线程上下文统计那边，有个坑，并行访问监听器列表发生并行访问异常，他那边是旧的
   hellhound版本，我们线上的21版本修复了。


昨天：
1、观察视频号灰度3: 点击cell-视频号首页启动，基本已经ok了(1500的用户)，总结了每个灰度跟进结果+原因
2、继续review：解决空日志问题 ---- ok，时长、事件都review了一遍
3、交互图

// 上周：
1、交互图，还差一些：如何通过操作页面和控件，自动采集想要采集的目标业务数据？？？
2、统计、观察 视频号灰度3  --- ing，（1）数据不错：98%~99%，（2）连sessoin、uba准确率都超过了90%：
  session: 90%~92%，uba：97%~98%，
 （3）前后台没有统计这个灰度版本，（4）跟圈外新版本上线
3、互斥session，防止重复点击，
4、视频号跟进问题解决文档 ---done
5、3月版本提测 --- done

///////////////////////////////////////// 上周 /////////////////////////////////////
1、完成交互图，讨论Android跨版本方案，敲定排期. ---- 完成
2、互斥session，防止重复点击     ---开发完成，下个版本上，这个版本不上
3、继续review u0，解决异常数据(前后台、页面) -----finder新版本发布
4、三月版本已经测试通过，并合入到发布分支了   ----测试通过，等待mar版本发布
5、周五提了需求，让朋友圈新增漏读feed，对其feed统计上报 ----- 不稳定，原因：下拉、按钮使用的，
  android中的实现跟原来滚动行为不同；已经解决俺就，还有个下拉行为需要适配

// 这周：
1、Android跨版本方案，确定排期，开始开发 ----已经开始了，被阻塞了
2、漏读feed下拉bug；今天完成，提测   ---视频号今天完成
3、观察u0
4、cgi熟悉
///////////////////////////////////////////////////////////////////////////////////
// 跨版本方案
1、版本升级导致的数据丢失：方案1：保存下发的两个版本，一个版本解析出坑，另一个版本继续解析；方案2：重启mm进程
2、支持push，兜底配单
3、下发配单：明文映射混淆，客户单上报时自己解混淆，上报明文

// 跨版本计划：
1、实现本地控件采集
2、接入上报
3、接入配置


// 控件行为在UBA中如何统计上报？？？？？？？？
首先，uba中不支持过滤统计，即：不支持像session page那样，下发一个配置，根据页面中配置的控件、事件来配置

上周：
1、本地debug控件：重复、丢失bug、有些UI控件是编译期下发的，有些晚，配特殊处理函数来监控->解决:增加了黑名
   单配置,解决重复监控的问题。
2、熟悉了网络CGI接口 -> 已经与舵哥联调通了。完善逻辑代码中...
3、新版本配单：补上哪些需要混淆文件的配单，上周已经完成
4、U0上的数据准确率：session与前后台校验：次数准确率：85%，其他都是90以上。视频号99%左右。

这周：
1、完善控件逻辑，debug增加新方案的业务参数获取，增加开关：旧方案+新方案切换；
2、灰度控件采集方案：全面采集；
3、分析 session与前后台校验 ，提升次数准确率；
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  -- - - - - - - - -

// 这周：
1、bug：voip浮窗bug解决
2、完善业务数据采集能力：扩展列表类型控件采集能力；终端开发+后台开发(新增了一些字段，获取明文和混淆的kv)
（1）终端这块儿的开发基本完成了：解析/采集/上报，三个模块
（2）后台开发机配置完成，可以访问和编译了，patchbuild也可以用了

// 下周：
1、接手跨版本开发后端开发项目，并与终端联调；
-----------------------------------------------------------------------------------


视频号列表采集：更完美的支持视频号的业务数据采集。。。
边缘计算怎么玩？
热门数据采集：
直播...
router
终端/后台的cgi改造

// 本周：
跨版本项目的后端开发：
（1）熟悉svrkit开发框架
（2）熟悉了基于构建系统Bazel的patchbuild构建工具，以及构建原理和appsvr项目情况
（3）撸了一遍appsvr中跨版本项目的后台代码逻辑，并加日志、发布到995环境中运行起来，调试前后端成功；

-----------------------------------------------------------------------------------
// 下周：
1、新增的列表字段解析脚本开发
a. 脚本也已经改了：
    a1. 这个方案不好, 需要改为无需解析配单的方案，释放业务逻辑，只需要解析map即可

2、跨版本方案，前后端联调
a. 终端这里的代码有些坑：列表的header跟业务相关，需要搞一下；还需要一个备用方案：保存当前列表控件对象的
   弱引用。用于辅助解析失败的场景；
b. 旧的python解析脚本方案不好(与业务太相关了)：
    b1. 需要改为无需解析配单的方案，释放业务逻辑，只需要解析map即可
c. mysql这里的connect/io可能出坑，导致携程一直释放不了；
方案：
    b1. 尝试上线了 “关闭mysql连接”的手段，还是会把携程一直释放不了
    b2. 需要先压测看看，然后把connect设置个超时，再测试；
    b3. 改为kv；已经熟悉了kv部分的的代码，写了几个过滤接口
c. 跟9月版本上线

3、思考跨版本项目的应用场景 ---roadmap

4、针对上周撸的后端的代码，有以下优化建议可以做：
（1）把解析规则通用化(以后新增、修改字段都可以自动解析mapping.txt/R_Shrinked.txt)出明文；
（2）通过cgi请求的若干业务，改造成通过配置自动化接入，通用模块和业务逻辑分离；

// 上周
1、改进终端+后端联调的发现问题
2、roadmap

-------------------------------------------------------------------------------
// 这周 下周继续：成果是完成改造。
1、压测发现的问题(分析core文件)，没有帮助，打算日志观察，改造成kv再观察；
    -> 给fun哥挪资源。可以同时进行。。。
2、客户端联调：在改造这块的明文/混淆名更通用
    -> 跟随kvtable改造一起在改，规划做一个实验：舍弃离线计算+存储(phthon脚本)，实时的从
    【蓝盾服务】那里下载混淆名单，并解析（混淆名单+解析内容，做LRU机制存储），
    返回给客户端，统计整个耗时；而不是定时去蓝盾上轮询任务。

3、服务端代码的实现：mysql->kv上线调试；明文混淆方式改造/独立出一个单独服务     // 穿插进行：仿造
  写着50%，-> 进行中：已经独立模块了，比较了ttlkv、strkv、tablekv之后，确定使用tablekv，但是好
  难用，在仿造写中。kv模块写完跟运维申请
4、bug：19943在分享场景时，平均时长太大10分钟 --> bug解决了，               // 穿插进行......
cgi对外接口调整；
-------------------------------------------------------------------------------
// kvtable非常难用：wtf，看了好多文章+wiki，才摸清楚；

--------------------------------------------------------------------------------
// 终端任务：
1、熟悉代码 + 构想埋点
2、解决19943+18054的数据问题

// 后台任务：
1、独立mmfddatahellsvr
2、接入tablekv，并修改明文/混淆名方案为通用方案；
3、实验：跨版本后台方案 从离线计算，改为 实时计算，监控整个流程的速度和资源使用情况，得到更实时的方案。
--------------------------------------------------------------------------------



/////////////////////////////////////////////////////////////////////////////
后台计划：
1、完成改造；
2、独立出一个服务，从appsvr中独立出来；
我有个想法，我觉得可以作为我们后续扩展动态采集能力的一个方向。
既然java函数在Native层都有一个函数地址对应的话，我们可以考虑更多，拿到目标函数中的所有信息：传参值、
返回值、目标函数在哪个函数中被调用、临时变量等。目前基于elf文件got/plt的hook，无论上在section或
segment上做工作其实都受到很多限制，只能hook系统本身的(glibc对应的)C/C++ API，可以考虑扩大范围，
去研究inline hook技术，这个是基于指令级别的，能够hook你想要的任意C/C++函数。
/////////////////////////////////////////////////////////////////////////////////

// kv应该使用：[mysql -> tableKV] -> []

/////////////////////////////////////////////////////////////////////////////////
// 一个明显问题是：针对类似19943这种一般协议上报，需要监控起来，提前发现问题，避免数据到用的时候才发
现有问题，两种方法：
方法1：设计协议时，留出校验字段，适合 “自校验”；
方法2：“旁路校验”，多条协议互相校验；
/////////////////////////////////////////////////////////////////////////////////

这个问题基本上定位清楚了：
1、在123、101、102等session中，且进入视频号feed分享页、profile页面时，用户收到聊天消息通知栏、
   VOIP场景，会导致页面切换、session切换之后，没有停止计算reporttype=1的时长；
2、部分机型存在适配性问题：切换到后台时，会导致当前页面、上一个页面、直到最终的LauncherUI页面都会被
   destroy掉，然后切换到前台后，从LauncherUI(微信首页)开始继续计算reportType=1时的19943时长，
   导致时长算大；

后续需要解决的问题是：
针对类似19943这种一般协议上报，需要监控起来，提前发现问题（灰度解决就发现问题），避免数据到用的时候才
发现有问题，两种方法：
方法1：设计协议时，留出校验字段，适合 “自校验”；
方法2：“旁路校验”，多条协议互相校验；
考虑到人力不足的情况，思考看能不能自动化解决（不一定可行），或简单化处理（例如：某些字段设置阈值的方式）。
////////////////////////////////////////////////////////////////////////////////////


// 2020-11-11 任务 **************************************************************
1. 调整动态对象采集计划:

- 旧的方案：（并不实用）
（1）bug修复
孤立对象的bug修复：采集逻辑的修复，只能做最简单的方法级别的修复，从目前直播业务的上报来看，简单的上报并不多，
大多数都是复杂的业务逻辑上报，如果有bug，也不是简单的修复几个方法就能解决的，一般都会伴随着全局(静态)变量、
类中变量的增删该查操作，以及逻辑条件的修改；
（2）采集方案动态，使用配单下发采集点（几乎没戏）
拆分复杂上报逻辑为一个个小的逻辑点，然后通过key组合成一条条的采集逻辑，操作复杂、较多的增加了工作量、且可行
实施性不高；

- 新的方案：
(1) 直接下发代码，即下发采集逻辑去采集
下发C/C++代码，即so库，这里主要解决两个问题：
问题1：获取Java层业务对象、以及其中的字段、方法、static字段、局部变量的能力
通过class对象的内存图谱识别；
问题2：合适的采集时机
各个入口地址识别 or 执行时拦截

在 Native 层进行 “动态” 采集，jni的api提供了可以访问java对象、字段、函数的能力；同时Java中的每一个
对象、函数都对应在Native层的一个地址，
因此在so中开发：根据上报逻辑，拦截这些函数，然后访问该对应类对象中的字段；
好处：1）与tinker不冲突；2）具备动态能力；3）可实施性高
// *****************************************************************************

上周任务：
1. 优化组那边监控TeleManager监听权限，使用Hellhound
2. review动态对象方案，修改方案；
3. t4上报；
自动分析出适配性的；
LXYX: 研究发现、纠错能力；；；；；；；；；；；；；；；；；；；；；；；；；；；；；；；；；；；；；；；；；；

- iWatch项目：
从视频号、直播项目的上报来看，采集数据的实际情况：
1. 要访问类中成员变量、函数参数、局部变量；
2. 要增删改查Java/Kotlin中的函数。
因此，定位做一个C/C++层的轻量级补丁，为何选择Native层，避免与Tinker版本管理冲突。
同时：tinker在发补丁时，很少会影响到上报；即使影响到了，通过 发现、iWatch热补丁修复技术，能快速发现、定位、
修复 bug.


//////////////////////////////////////////////////////////////////////////////////
// 上周
1. t4需求:
2. 数据采集项目：热补丁：我 and 晨
   (1) 预检验:
    1）亟待解决的是：代码改动导致的反射失败：@Keep + 在当前模块中写一个帮助类，然后@Keep自己的类来解决
    2）bug识别：本地的bug大多数都不是显性的，跟环境强相关；
   bug自动识别更多是需要后台+web来搞：像ilog一样，通过在web上配置一些需要具有校验关系的字段来识别bug.
   客户端在不增加额为工作的情况下，无能为力；

   (2) 热补丁: 作用：动态化、缓解写上报的压力、针对某些版本修复上报bug的能力；
   结合上报的经验来看，热补丁需要具备的能力: 字段、方法、类的 增加、修改(替换)
   版本管理与tinker冲突解决: ？？？？？？ tinker是: dex替换；iWatch是: C/C++方法(函数)、字段地址
   替换(已经实现了)；
   1) demo实现：替换能力 and 增加能力
   不影响tinker版本的方案：
   1. 下发jar包方式 代替 dex diff方案；
   2. hook能力
   3. jar包如果hook失败，上报对应的失败信息，例如：版本号等，线下再针对该版本重新下发jar包来解决问题；

规划：
1、明确目标：热补丁能力、tinker不冲突的能力
2、demo方案验证
 2.1、demo：替换能力：字段、方法
 2.2、demo：新增能力：字段、方法
3、tinker版本冲突解决：
4、版本兼容

// 这周
1. t4需求；
2. demo完善：增加新增能力: 字段、类、方法。
//////////////////////////////////////////////////////////////////////////////////////

【修复问题】
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~ ~
- iWatch定位调整：
不是一个传统意义上的热补丁，只是用于 "数据统计的补丁"，即所需要的功能是：
1. 任意方法(函数)内插入一段统计代码(或函数)：
   (1) 统计代码(或函数)会访问当前类中的字段(成员变量)、当前方法中的形参、临时变量
   (2) 统计代码(或函数)需要在特定逻辑下插入
   (3) 在当前类中新增方法、字段的能力：方法需要访问当前类中的成员变量、调用其他函数的能力(优先级较低)
2. 新增统计类(class)的能力
   可以调用其他类中的成员变量、成员方法

- 方案：
方案1：类中方法的整体替换：优点：简单；缺点：依赖 apk 的 diff 工具 diff 出补丁 jar 包
方案2：类的整体替换
方案3：在方法特定逻辑中插入统计代码
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~

// iWatch新的思路:
- 只替换目标类(c0)的方法(m0)，新的方法(m1)在新的类(c1)中实现，c1中可以保存任意增加字段、方法、调用其他
  类等等.
- 如何解决上面提到的问题：可以解决.
- iwatch 没有写死 ArtMethod，因此比 AndFix 适配性更好

~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
晨哥：
1. 完成 demo-so 的开发，有  getartmethodaddress、jni_compile功能，包括开辟内存  的操作，
   修复某个方法  将修复包  编译后   替换 method address 逻辑地址，执行新的方法。 --epic

处理修复方案本身之外，我们考虑：
1. 与旧的 tinker 兼容；基本要求：不能crash、不能影响性能、不能影响tinker补丁(业务bug修复第一位的，
   我们是采集上报补丁);
2. 能够即使发现数据上报或采集的bug方案：比如 我在编译期识别哪些类被我标记修改了会导致上报可能不准确；咱们
   的热补丁在遇到
   tinker下发的reversion与我们采集的不同时，放弃上报补丁，实时上报到我们的后台告警，及时修复方案等等
同步一下：底层方案可能造成crash
   上周我找了负责tinker的同事咨询了，他们提了一些建议：1. ，例如：gc时地址被改变；2. 在art虚拟机层
   修改代码，基本不会影响到tinker本身的补丁执行；

// 上周:
1. t4新需求：连麦主播端，其他未做完
2. iWatch补丁，突破：方法体访问类、对象中成员变量的坑；与 tomystang 沟通与 tinker 的影响:
   (1) gc对地址偏移的影响；已经解决;
   (2) 在art虚拟机层修改类中成员的acc_flags，不影响tinker补丁;
3. 晨哥task：仿造 epic 剪裁出一个 方法级别的 hook，暂时没有新意，这周

// 这周:
1. t4新需求
2. dex diff 研究 和 引入，使 demo 可初步具有灰度发布的完整能力.

// 需要解决的问题：
1. 版本管理，与tinker解冲突；
2. 合入主线版本的时机；

// 突破1：目标 method 中访问了当前类中的 field：反射 or 继承并修改 acc_flags.
// 突破2：目标 method 所属 class 是匿名内部类: 起始针对固定版本，匿名内部类是不存在的，即：编译后都对应同一个类名,
         例如：com.habbyge.iwatch.test.MainActivity$5.

// 仍有两个大问题需要突破的: ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
1. dex diff
2. inline 函数的 fix.

// 上周
1. inline 函数；
2. dex diff
3. t4需求，t5加入了：朋友圈广告透传

// 这周
1. dex diff
2. ArtMethod大小不稳定


////////////////////////////////////////////////////////////////////////////////////////////////////
-------------------------------------- 数据统计上报开发花费 --------------------------------------
// 记录1. zeus计划1月13号发出去;
直到13号上午还未完全合入的功能有：附近直播的功能；看剧个人状态；下拉任务栏改版 都没有合入；
以上三个业务我的开发时间分别是：小时级；
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
解决的bug:
是关于 “朋友圈、聊天消息快速滚动 anr” 解决方案：
加了两个方案，
方案1：与朋友圈分时采集机制方案相同(跑了两年，通过了测试组掉帧测试，所以可作为参考)，采用限速机制，1000px/s，才去采集
方案2：限时间间隔 50ms 采集一次数据
通过云端配置，可切换方案1和2，方案2可调采集间隔时长
默认方案2
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
iwatch 立项的理由是:
1. 业务上报需求按周接
   不硬性跟微信tinker(一般做feature发布)、主版本发布，这就要求跟web、后台需求一样，随时上线呢，那么必然需要自己的热补丁，
   来达到随时发布的效果；
2. 数据统计、上报的需求的特点：碎片化严重，即随时随地的有需求、改需求；
3. 业务开发完成后，留下写上上报的时间非常短，还得留给数据测试时间，造成加班加点都完不成上报需求；
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
iwatch 细节优化：
1. 需要加锁 + 条件变量来保护 ？？？？？？难做到......
1.1 hook替换时，原始函数刚好执行到这里；需要互斥
1.2 正在恢复时，业务函数正好执行到这里，反之情况也一样；

2. 去重机制：重复hook、重复恢复等；
3. base版本不符合 patch 时的恢复机制
4. 跟优化组那边沟通：包以aar形式(内含核心so文件iwatch_0_1.so)版本号，分别支持多CPU平台的32bit/64bit aar.
-----------------------------------------------------------------------------------------------

业务上报最紧急的已经上了
////////////////////////////////////////////////////////////////////////////////////////////////////

自动化 Patth 线上所有版本，自动化的 patch 所有版本 ------ 需要考虑......

////////////////////////////////////////////////////////////////////////////////////////////////////
1. 上报：8.0 done，t5还有两个；新增了2个；
2. anr：搞定了滚动；还有初始化的；已经ok了，这周发test包搞验证；
3. iwath:
（1）patch tools 优化：1）自动化打上注解；2）多dex支持；
（2）增加字段、方法、类的能力：主要涉及ClassLoader的修改；
（3）按照要求 namespace 隔离；
////////////////////////////////////////////////////////////////////////////////////////////////////